{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6d5f4c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  \n",
    "# üßÅ Limpeza e tratamento de dados de CGM (monitoramento cont√≠nuo de glicemia)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5815ac",
   "metadata": {},
   "source": [
    "## 1. Carregando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1033e358-f98f-421b-b8b1-a1d0dea9c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d404a1",
   "metadata": {},
   "source": [
    "## 2. Extraindo e visualizando o dataframe; padronizando os nomes das vari√°veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset extra√≠do pelo RStudio atrav√©s do reposit√≥rio \n",
    "# https://rdrr.io/github/personalscience/psi-shiny-cgm/man/sample_libreview_df.html\n",
    "df_a = pd.read_csv('./sample_libreview_df_raw.csv')\n",
    "df_raw = df_a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "No atributo columns (do tipo √≠ndice) do objeto df_raw, nosso dataframe, iremos formatar\n",
    "todos os seus elementos, isto √©, os nomes das colunas. Para isso, utilizamos o acessor .str, \n",
    "que nos permite aplicar m√©todos de strings para todos os elementos do √≠ndice/vetor.\n",
    "Os m√©todos utilizados s√£o: \n",
    "- lower(): torna todos os caracteres min√∫sculos;\n",
    "- strip(): remove espa√ßos em branco das extremidades da string;\n",
    "- replace(,): substitu√≠mos o elemento da esquerda, sempre que ele aparecer, pelo da \n",
    "direita. No nosso caso, trocamos um espa√ßo em branco por nenhum espa√ßo, e \":\" por nenhum espa√ßo.\n",
    "'''\n",
    "\n",
    "df_raw.columns = df_raw.columns.str.lower().str.strip().str.replace(' ', '').str.replace(':', '')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c753351e",
   "metadata": {},
   "source": [
    "## 3. Verificando a hierarquia entre 'value', 'strip', 'scan' e 'hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_herda_exclui(df, col_time='time', col_alvo='value', col1='strip', col2='scan', col3='hist'):\n",
    "    \"\"\"\n",
    "    Preenche os NaNs de `col_alvo` com prioridade:\n",
    "    1. Usa `col1` se dispon√≠vel.\n",
    "    2. Caso contr√°rio, usa `col2`.\n",
    "    3. Caso contr√°rio, usa `col3`.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 0 = n√£o foi preenchido por outra coluna, 1 foi por col1, 2 por col2 e 3 por col3.\n",
    "    df['preenchido_por'] = 0\n",
    "\n",
    "    # vetores (Series), onde: o primeiro tem valores True nos √≠ndices em que col_alvo √© NaN; \n",
    "    # o segundo tem valores True onde col1 n√£o √© NaN\n",
    "    cond1 = df[col_alvo].isna() & df[col1].notna() \n",
    "    # fa√ßo a substitui√ß√£o nessas posi√ß√µes\n",
    "    df.loc[cond1, col_alvo] = df.loc[cond1, col1]\n",
    "    df.loc[cond1, 'preenchido_por'] = 1\n",
    "\n",
    "    # Fa√ßo o mesmo com as linhas restantes de col_alvo que continuam NaN, mas agora\n",
    "    # comparando com os valores de col2 e col3\n",
    "    cond2 = df[col_alvo].isna() & df[col2].notna()\n",
    "    df.loc[cond2, col_alvo] = df.loc[cond2, col2]\n",
    "    df.loc[cond2, 'preenchido_por'] = 2\n",
    "\n",
    "    cond3 = df[col_alvo].isna() & df[col3].notna()\n",
    "    df.loc[cond3, col_alvo] = df.loc[cond3, col3]\n",
    "    df.loc[cond3, 'preenchido_por'] = 3\n",
    "\n",
    "    # Agora, vamos ordenar por prioridade e eliminar duplicatas no tempo\n",
    "    df = df.sort_values(by=[col_time, 'preenchido_por'])  # menor preenchido_por tem maior prioridade\n",
    "    df = df.drop_duplicates(subset=col_time, keep='first').reset_index(drop=True)\n",
    "\n",
    "    # Removo a coluna que indica de qual medi√ß√£o o value foi advindo\n",
    "    df = df.drop(columns=['preenchido_por'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_raw = value_herda_exclui(df_raw)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7a18e",
   "metadata": {},
   "source": [
    "## 4. Certificando os tipos de dados e removendo vari√°veis desnecess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ca805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertemoscoluna 'time' para o tipo datetime\n",
    "df_raw['time'] = pd.to_datetime(df_raw['time'], errors = 'coerce') \n",
    "# a coluna 'value' se torna num√©rica\n",
    "df_raw['value'] = pd.to_numeric(df_raw['value'], errors = 'coerce') \n",
    "\n",
    "# OBS: errors = 'coerce' faz com que elementos que n√£o estejam num formato v√°lido para\n",
    "# serem convertidos para datetime retornem NaT, e os que n√£o possam ser convertidos para\n",
    "# int ou float (num√©rico) retornem NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae39c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando as colunas que n√£o ser√£o utilizadas\n",
    "df_raw = df_raw.drop(columns=['unnamed0', 'strip', 'hist', 'scan', 'food', 'user_id'])\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bba65",
   "metadata": {},
   "source": [
    "## 5. Eliminando os valores nulos e absurdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de quantos valores nulos (NaN ou NaT) temos em cada coluna de df_raw\n",
    "# df_raw.isnull() retorna um dataframe com True e False em cada c√©lula. True, se a c√©lula tem\n",
    "# valor NaN ou NaT, e False em caso contr√°rio. O m√©todo sum(axis = 0) soma a quantidade de cada coluna.\n",
    "# Como True corresponde ao valor 1 e False a 0, teremos assim a soma dos valores nulos.\n",
    "\n",
    "print('Valores nulos antes: \\n')\n",
    "print(df_raw.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as linhas em que 'time' ou 'value' tem valor nulo\n",
    "df_raw = df_raw.dropna(subset=['time','value'])\n",
    "\n",
    "# Excluindo as linhas em que 'value' tem um poss√≠vel ru√≠do\n",
    "df_raw = df_raw[(df_raw['value'] > 0) & (df_raw['value'] < 500)]\n",
    "\n",
    "# Organizando o dataframe por 'time' crescente, e resetando os √≠ndices, j√° que\n",
    "# ao excluirmos linhas, a linha com o √≠ndice √© exclu√≠da. Agora, temos √≠ndices ordenados e\n",
    "# sequenciados novamente de 0 ao fim do dataframe.\n",
    "df_raw = df_raw.sort_values(by='time').reset_index(drop=True) \n",
    "\n",
    "# Esse √© o dataframe apenas com dados medidos\n",
    "df_raw "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a435c",
   "metadata": {},
   "source": [
    "## 6. Verificando se h√° grandes hiatos de tempo em 'time' e preenchendo-os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_hiatos(df, col_time='time', col_val='value', hiato=3, x='15min', st=15, e=15):\n",
    "    \"\"\"\n",
    "    Preenche hiatos (lacunas) maiores ou iguais a hiato no DataFrame,\n",
    "    inserindo linhas com timestamps intermedi√°rios e valores NaN.\n",
    "\n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original contendo ao menos as colunas de tempo e valor.\n",
    "    col_time : str, default 'time'\n",
    "        Nome da coluna com timestamps (deve ser datetime).\n",
    "    col_val : str, default 'value'\n",
    "        Nome da coluna com os valores (num√©ricos, pode conter NaNs).\n",
    "    hiato : float, default 3\n",
    "        M√≠nimo intervalo em horas para considerar um hiato para preenchimento.\n",
    "    x : str, default '15min'\n",
    "        Frequ√™ncia para preenchimento dos timestamps intermedi√°rios.\n",
    "    st : float, default 15\n",
    "        Determina ap√≥s quantos minutos do valor antes do hiato iremos colocar nosso primeiro preenchimento\n",
    "    e : float, default 15\n",
    "        Determina a dist√¢ncia m√≠nima que o √∫ltimo preenchimento pode estar do primeiro timestamp ap√≥s o hiato\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Novo DataFrame com os hiatos preenchidos com linhas contendo NaN em col_val,\n",
    "        ordenado por tempo e com √≠ndice resetado.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    # criando uma coluna que mede a diferen√ßa em horas entre um elemento de 'col_time' e o elemento 'anterior'\n",
    "    df['diff_horas'] = (df[col_time].diff().dt.total_seconds())/(60 * 60)\n",
    "\n",
    "    # preencheremos somente hiatos maiores ou iguais a {hiato}\n",
    "\n",
    "    # √≠ndices dos elementos que est√£o imediatamente antes de cada hiato\n",
    "    inds_i = df[df['diff_horas'] >= hiato].index - 1\n",
    "    # √≠ndices dos elementos que est√£o ao fim de cada hiato\n",
    "    inds_f = df[df['diff_horas'] >= hiato].index\n",
    "\n",
    "    # N√∫mero de hiatos:\n",
    "    print(f'O total de hiatos de {hiato} horas encontrado foi:', len(inds_i), '\\nIremos preench√™-los com mais marca√ß√µes.\\n')\n",
    "\n",
    "    # Novas linhas, com respectivos datatimes, que iremos adicionar ao df ap√≥s o processo.\n",
    "    # Come√ßamos com uma lista vazia.\n",
    "    linhas = []\n",
    "\n",
    "    # Pegaremos cada √≠ndice de in√≠cio e fim de hiato, acessaremos o elemento correspondente em 'col_time' e\n",
    "    # faremos o preenchimento desse hiato\n",
    "\n",
    "    for i in range(len(inds_i)):\n",
    "        inicio = inds_i[i] # √≠ndice in√≠cio hiato (rodaremos a lista de √≠ndices)\n",
    "        fim = inds_f[i] # √≠ndice fim hiato\n",
    "\n",
    "        start_time = df.loc[inicio, col_time] # acessando df na coluna 'col_time' na posi√ß√£o in√≠cio\n",
    "        end_time = df.loc[fim, col_time] # na posi√ß√£o fim\n",
    "\n",
    "        # Lista com os timestamps criados\n",
    "        range_time = pd.date_range(start=start_time + pd.Timedelta(minutes=st), # come√ßaremos o preenchimento 15 minutos ap√≥s in√≠cio do hiato\n",
    "                                            end=end_time - pd.Timedelta(minutes=e), # terminaremos no m√°ximo at√© 15 minutos antes do fim do hiato\n",
    "                                            freq=x) # preencheremos de 15 em 15 minutos esse hiato\n",
    "        \n",
    "        # Colocaremos cada um desses timestamps dentro do dicion√°rio com as chaves 'time'\n",
    "        # e 'value', essas √∫ltimas recebendo NaN como valores. O objeto 'linhas' receber√° esse dicion√°rio.\n",
    "        for timestamp in range_time:\n",
    "            linhas.append({col_time: timestamp, col_val: np.nan}) \n",
    "\n",
    "\n",
    "    # O dicion√°rio 'linhas' se torna o dataframe 'df_linhas'\n",
    "    df_linhas = pd.DataFrame(linhas)\n",
    "\n",
    "    # Concatenamos o dataframe df, mas sem a coluna diff_horas (agora desnecess√°ria), com\n",
    "    # o dataframe df_linhas, que tem as mesmas colunas (value e time).\n",
    "    # ignore_index = True evita √≠ndices duplicados (exemplo: o √≠ndice 2 em ambos os dataframes), \n",
    "    # e reseta o √≠ndice do dataframe concatenado, para que v√° de 0 at√© o √∫ltimo elemento da lista, de maneira sequencial\n",
    "    df = pd.concat([df.drop(columns=['diff_horas']), df_linhas], ignore_index=True)\n",
    "\n",
    "    # Ordenamos o dataframe por 'time' crescente e mais uma vez resetamos os √≠ndices (a redund√¢ncia\n",
    "    # se deve apenas √† uma quest√£o de organiza√ß√£o)\n",
    "    df = df.sort_values(by=col_time).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_tempos = preencher_hiatos(df_raw)\n",
    "\n",
    "# Esse √© o dataframe com os dados originais e novas estampas de tempo, mas sem preencher os valores\n",
    "# correspondentes a elas\n",
    "\n",
    "df_tempos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d3644",
   "metadata": {},
   "source": [
    "## 7. Atribuindo valores aos novos timestamps criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "# Fun√ß√£o para gerar valores de uma normal truncada (com limite inferior e superior)\n",
    "def amost_norm_tr(mu, sigma, low=0, high=500):\n",
    "    a, b = (low - mu) / sigma, (high - mu) / sigma\n",
    "    return truncnorm.rvs(a, b, loc=mu, scale=sigma)\n",
    "\n",
    "def imp_est_value(df, col_time='time', col_val='value', n=20):\n",
    "     \n",
    "    \"\"\"\n",
    "    Imputa valores ausentes em uma coluna de medi√ß√µes temporais usando normal truncada.\n",
    "\n",
    "    A imputa√ß√£o √© feita individualmente para cada timestamp com valor ausente,\n",
    "    baseado na m√©dia e desvio padr√£o calculados a partir das n vizinhas observa√ß√µes\n",
    "    mais pr√≥ximas no tempo (n/2 anteriores e n/2 posteriores), que:\n",
    "      - possuem o mesmo valor da hora (0 a 23) do dado ausente,\n",
    "      - possuem valores observados (n√£o NaN),\n",
    "      - e s√£o distintas do pr√≥prio dado ausente.\n",
    "\n",
    "    Para garantir independ√™ncia estat√≠stica e evitar vi√©s, a m√©dia e desvio padr√£o\n",
    "    s√£o sempre calculados apenas com os dados originais observados (n√£o imputados),\n",
    "    mesmo durante o processo de m√∫ltiplas imputa√ß√µes.\n",
    "\n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame contendo as colunas de tempo e valores a imputar.\n",
    "\n",
    "    col_time : str, default 'time'\n",
    "        Nome da coluna no DataFrame que cont√©m as datas e hor√°rios completos (formato datetime).\n",
    "\n",
    "    col_val : str, default 'value'\n",
    "        Nome da coluna contendo os valores num√©ricos onde podem existir dados ausentes (NaN).\n",
    "\n",
    "    n : int, default 20\n",
    "        N√∫mero total de vizinhos temporais a considerar para c√°lculo de m√©dia e desvio padr√£o.\n",
    "        A fun√ß√£o busca n//2 observa√ß√µes anteriores e n//2 posteriores mais pr√≥ximas no tempo.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        C√≥pia do DataFrame original com os valores ausentes imputados.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Certificar que col_time est√° no formato datetime\n",
    "    df[col_time] = pd.to_datetime(df[col_time])\n",
    "\n",
    "    # criar a coluna _hora\n",
    "    df['_hora'] = df[col_time].dt.hour\n",
    "\n",
    "    # garante ordena√ß√£o pelo tempo\n",
    "    df.sort_values(by=col_time, inplace=True)\n",
    "\n",
    "    # Base fixa s√≥ com dados originais (n√£o imputados)\n",
    "    df_original = df[df[col_val].notna()].copy()\n",
    "\n",
    "    # coluna que vai dizer se o valor foi estimado ou n√£o\n",
    "    df['is_imputed'] = False\n",
    "\n",
    "    # ind√≠ces de elementos de col_val com valor NaN\n",
    "    inds_nan = df[df[col_val].isna()].index\n",
    "    \n",
    "    # N√∫mero de medi√ß√µes reais √† esquerda e √† direita\n",
    "    metade = n // 2\n",
    "\n",
    "    for ind in inds_nan:\n",
    "        timestamp_faltante = df.at[ind, col_time] # selecionar o timestamp sem valor\n",
    "        hora_faltante = df.at[ind, '_hora'] # selecionar a hora do timestamp sem valor\n",
    "\n",
    "        # Filtrar dados com a mesma hora e valores n√£o ausentes\n",
    "        df_valid = df_original[df_original['_hora'] == hora_faltante]\n",
    "\n",
    "        # Vizinhos anteriores (com timestamp < faltante), pega os mais pr√≥ximos\n",
    "        anteriores = df_valid[df_valid[col_time] < timestamp_faltante].tail(metade)\n",
    "\n",
    "        # Vizinhos posteriores (com timestamp > faltante), pega os mais pr√≥ximos\n",
    "        posteriores = df_valid[df_valid[col_time] > timestamp_faltante].head(metade)\n",
    "\n",
    "        # Junta os vizinhos do dado faltante\n",
    "        amostras = pd.concat([anteriores, posteriores])\n",
    "\n",
    "        if len(amostras) >= 2:\n",
    "            # Dist√¢ncia em segundos at√© o timestamp ausente\n",
    "            amostras['delta'] = (amostras[col_time] - timestamp_faltante).dt.total_seconds().abs()\n",
    "\n",
    "            # Peso inversamente proporcional ao quadrado da dist√¢ncia (suaviza√ß√£o forte)\n",
    "            amostras['peso'] = 1 / (1 + amostras['delta'])**2\n",
    "\n",
    "            # Extrai valores e pesos\n",
    "            valores = amostras[col_val].values\n",
    "            pesos = amostras['peso'].values\n",
    "\n",
    "            # M√©dia ponderada\n",
    "            mu_ponderado = np.average(valores, weights=pesos)\n",
    "\n",
    "            # Vari√¢ncia e desvio padr√£o ponderados\n",
    "            var_ponderada = np.average((valores - mu_ponderado) ** 2, weights=pesos)\n",
    "            sigma_ponderado = np.sqrt(var_ponderada)\n",
    "\n",
    "            # Imputa o valor usando normal truncada\n",
    "            imputado = round(amost_norm_tr(mu_ponderado, sigma_ponderado), 1)\n",
    "            df.at[ind, col_val] = imputado\n",
    "            df.at[ind, 'is_imputed'] = True  # Marca como imputado\n",
    "\n",
    "    # Remove coluna auxiliar\n",
    "    df.drop(columns=['_hora'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_raw = imp_est_value(df_raw)\n",
    "df_est = imp_est_value(df_tempos)\n",
    "\n",
    "# Novo dataframe, com os valores medidos e os valores estimados\n",
    "df_est\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ce2f0",
   "metadata": {},
   "source": [
    "## 8. Granula√ß√£o de 'time' em 'date', 'hour', 'hour_minute', 'weekday' e 'hour_cont'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def granular(df, col_time='time', col_val='value', imp='is_imputed'):\n",
    "    \"\"\"\n",
    "    Adiciona colunas derivadas de tempo para an√°lise estat√≠stica e manipula√ß√£o temporal.\n",
    "\n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame com uma coluna datetime.\n",
    "    col_time : str, default 'time'\n",
    "        Nome da coluna que cont√©m timestamps (deve ser do tipo datetime ou convers√≠vel).\n",
    "    col_value : str, default 'value'\n",
    "        Nome da coluna que cont√©m medi√ß√µes.\n",
    "    imp : str, default 'is_imputed'\n",
    "        Nome da coluna que informa se o valor correspondente foi estimado ou n√£o.\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame com as colunas adicionais:\n",
    "            - 'date' : data (sem hor√°rio)\n",
    "            - 'hour' : hora inteira\n",
    "            - 'hour_minute' : string com hora e minuto no formato HH:MM\n",
    "            - 'weekday' : nome do dia da semana\n",
    "            - 'hour_cont' : hora com fra√ß√£o decimal (ex: 14.25 para 14:15)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[col_time] = pd.to_datetime(df[col_time])\n",
    "    df['date'] = df[col_time].dt.date\n",
    "    df['hour'] = df[col_time].dt.hour\n",
    "    df['hour_minute'] = df[col_time].dt.strftime('%H:%M')\n",
    "    df['weekday'] = df[col_time].dt.day_name()\n",
    "    df['hour_cont'] = (df[col_time].dt.hour + df[col_time].dt.minute / 60).round(2)\n",
    "\n",
    "    colunas_ordenadas = [col_time, 'date', 'hour_minute', col_val, imp, 'weekday', 'hour', 'hour_cont']\n",
    "    df = df[colunas_ordenadas]\n",
    "    return df\n",
    "\n",
    "df_raw = granular(df_raw)\n",
    "df_est = granular(df_est)\n",
    "\n",
    "df_est.to_csv(\"estat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db483163",
   "metadata": {},
   "source": [
    "## 9. Organiza√ß√£o final das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ccc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0258b7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  \n",
    "# üîç An√°lise Explorat√≥ria de Dados\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de linhas e colunas:\\n', df_est.shape, '\\n\\n---\\n')\n",
    "print('Colunas presentes:\\n', df_est.columns, '\\n---\\n')\n",
    "print('Tipo de dados:\\n', df_est.dtypes, '\\n\\n---\\n')\n",
    "print('Quantidade de dados √∫nicos:\\n', df_est.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6642d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est['value'].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de apari√ß√µes dos valores medidos para glucose no fluido intersticial (mg/dL)')\n",
    "sns.histplot(df_est['value'], kde=True)\n",
    "plt.ylabel('N√∫mero de apari√ß√µes')\n",
    "plt.xlabel('Glicose (mg/dL)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de medi√ß√µes por dia da semana')\n",
    "df_est['weekday'].value_counts().plot.bar()\n",
    "plt.ylabel('Quantidade de medi√ß√µes')\n",
    "plt.xlabel('Dia da semana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('M√©dia das medi√ß√µes nos dias em que houve aferi√ß√£o')\n",
    "df_est.groupby('time')['value'].mean().plot()\n",
    "plt.ylabel('Glicose (mg/dL)')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N√∫mero de medi√ß√µes por data')\n",
    "df_est.groupby('date').size().plot(kind='bar', figsize=(15, 4), title='Quantidade de medi√ß√µes por data')\n",
    "plt.ylabel('Quantidade de aferi√ß√µes')\n",
    "plt.xlabel('Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7610b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de medi√ß√µes por hora')\n",
    "contagem_horas_ord = df_est['hour'].value_counts().sort_index()\n",
    "contagem_horas_ord.plot.bar()\n",
    "plt.ylabel('Quantidade de medi√ß√µes')\n",
    "plt.xlabel('Hora do dia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703df6b",
   "metadata": {},
   "source": [
    "## 1. H√° rela√ß√£o entre o valor da glicemia (value) e o hor√°rio do dia (time)? Em quais horas do dia h√° maiores picos de glicemia? Em quais horas do dia h√° menores valores de glicemia? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de m√©dia, m√≠nimo e m√°ximo valores de glicemia (mg/dL) por hora do dia\n",
    "df_est.groupby('hour')['value'].agg(['mean', 'min', 'max']).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico da m√©dia de glicemia por hora do dia \n",
    "media_por_hora = df_est.groupby('hour')['value'].mean()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=media_por_hora.index, y=media_por_hora.values)\n",
    "plt.title('M√©dia de glicemia por hora do dia')\n",
    "plt.xlabel('Hora do dia')\n",
    "plt.ylabel('Glicemia (mg/dL)')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f178b",
   "metadata": {},
   "source": [
    "# 2. Nos dados analisados, qual a porcentagem do tempo o paciente est√° dentro, acima ou abaixo dos valores de refer√™ncia ideais? \n",
    "\n",
    "##### Valores ideais:\n",
    "##### TIR time in range: ‚â• 70% do tempo entre 70-180 mg/dL\n",
    "##### TBR time below range: < 4% do tempo abaixo de 70 mg/dL\n",
    "##### TBR time very below range: < 1% abaixo de 54 mg/dL\n",
    "##### TAR time above range: < 25% acima de 180 mg/dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09272d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df_raw)\n",
    "tar = len(df_raw[df_raw['value'] > 180]) / total * 100\n",
    "tir = len(df_raw[(df_raw['value'] >= 70) & (df_raw['value'] <= 180)]) / total * 100\n",
    "tbr = len(df_raw[df_raw['value'] < 70]) / total * 100\n",
    "tvbr = len(df_raw[df_raw['value'] < 54]) / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_check = '‚úîÔ∏è' if tar < 25 else '‚ùå'\n",
    "tir_check = '‚úîÔ∏è' if tir >= 70 else '‚ùå'\n",
    "tbr_check = '‚úîÔ∏è' if tbr < 4 else '‚ùå'\n",
    "tvbr_check = '‚úîÔ∏è' if tvbr < 1 else '‚ùå'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'| TAR time above range      | {tar:.1f}%  | < 25% acima de 180 mg/dL           | {tar_check} |')\n",
    "print(f'| TIR time in range         | {tir:.1f}% |  ‚â• 70% do tempo entre 70-180 mg/dL | {tir_check} |')\n",
    "print(f'| TBR time below range      | {tbr:.1f}% | < 4% do tempo abaixo de 70 mg/dL   | {tbr_check} |')\n",
    "print(f'| TBR time very below range | {tvbr:.1f}%  | < 1% abaixo de 54 mg/dL            | {tvbr_check} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b7f74",
   "metadata": {},
   "source": [
    "# 3. Dentro do per√≠odo de medi√ß√£o, houve algum dia em que a m√©dia de glicemia destoou muito do normal? Em quais momentos houve epis√≥dios de hiper (>180mg/dL) e hipoglicemia? (<70mg/dL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "mapa_medicoes = df_raw[['value']]\n",
    "mapa_medicoes = mapa_medicoes.T\n",
    "\n",
    "faixas = [0, 70, 180, df_raw['value'].max() + 1]\n",
    "\n",
    "# Cores suaves e harm√¥nicas:\n",
    "colors = ['#7DA6C1', '#A3C293', '#D46256']\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(faixas, cmap.N)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 2))\n",
    "sns.heatmap(mapa_medicoes, cmap=cmap, norm=norm, cbar_kws={'label': 'Glicose (mg/dL)'})\n",
    "plt.yticks([], [])\n",
    "plt.xlabel(\"Leituras\")\n",
    "plt.title(\"Mapa de calor com destaque para medi√ß√µes individuais acima de 180 e abaixo de 70\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9ad97",
   "metadata": {},
   "source": [
    "# 4. Qu√£o r√°pido a curva de glicemia tende a voltar para os valores de refer√™ncia ideais? H√° alguma vari√°vel que influencia o tempo de retorno?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570380f2",
   "metadata": {},
   "source": [
    "# 5. H√° diferen√ßa significativa da m√©dia de glicemia entre dias da semana? (dias √∫teis, fins de semana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "tabela = df_raw.pivot_table(index='hour', columns='weekday', values='value', aggfunc='mean')\n",
    "max_val = df_raw['value'].max()\n",
    "\n",
    "colors = ['#E99A8B', '#A3C293', '#D46256'] \n",
    "glucose_range = [0, 70, 140, max_val + 1]\n",
    "\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(glucose_range, cmap.N)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(tabela, annot=True, fmt=\".1f\", cmap=cmap, norm=norm, cbar_kws={'label': 'Glicose (mg/dL)'})\n",
    "plt.title(\"Glicose m√©dia por hora do dia e por dia da semana\")\n",
    "plt.ylabel(\"Hora do dia\")\n",
    "plt.xlabel(\"Dia da semana\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_por_dia = df_raw.groupby('weekday')['value'].mean().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "]).reset_index()\n",
    "\n",
    "mapa_mediageral = pd.DataFrame([media_por_dia['value'].values], columns=media_por_dia['weekday'].values)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "sns.heatmap(mapa_mediageral, annot=True, fmt=\".1f\", cmap=\"crest\", cbar_kws={'label': 'Glicose m√©dia (mg/dL)'})\n",
    "plt.title(\"M√©dia de glicose no fluido intersticial por dia da semana\")\n",
    "plt.yticks([], []) \n",
    "plt.xlabel(\"Dia da semana\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5a95a",
   "metadata": {},
   "source": [
    "# 6. H√° varia√ß√£o de glicemia significativa durante o per√≠odo noturno e durante a manh√£ (4h-8h)? (dawn phenomenon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico da m√©dia de glicemia por hora do dia \n",
    "media_por_hora = df_raw.groupby('hour')['value'].mean()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=media_por_hora.index, y=media_por_hora.values)\n",
    "plt.title('M√©dia de glicemia por hora do dia')\n",
    "plt.xlabel('Hora do dia')\n",
    "plt.ylabel('Glicemia (mg/dL)')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ba65c",
   "metadata": {},
   "source": [
    "# 7. Qual a glicemia m√©dia geral do per√≠odo analisado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_global = df_raw['value'].mean()\n",
    "media_check = '‚úîÔ∏è' if media_global > 70 and media_global < 180 else '‚ùå'\n",
    "print('M√©dia geral:', media_global, media_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbb7e8",
   "metadata": {},
   "source": [
    "# 8. Qual o desvio padr√£o ou coeficiente de varia√ß√£o (CV%) da glicemia?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ccc5e",
   "metadata": {},
   "source": [
    "# 9. Quais dias em que houve mais instabilidade (maior varia√ß√£o)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e716a",
   "metadata": {},
   "source": [
    "# 10. H√° consist√™ncia nos dados? √â poss√≠vel prever quais horas do dia haver√° oscila√ß√µes significativas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4af60d",
   "metadata": {},
   "source": [
    "# 11. H√° alguma diferen√ßa entre a m√©dia da primeira e √∫ltima metade da amostra? Houve alguma diferen√ßa no controle ao longo do m√™s ou permaneceu constante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbf126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. N√∫mero e dura√ß√£o m√©dia dos epis√≥dios de hipoglicemia e hiperglicemia\n",
    "# 13. Velocidade m√©dia de subida e queda da glicemia\n",
    "# 14. Tempo em hipoglicemia noturna (00h‚Äì6h)\n",
    "# 17. Predi√ß√£o simples com regress√£o ou modelo de baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a801d",
   "metadata": {},
   "source": [
    "# Predi√ß√£o com regress√£o linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154d9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c678fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_raw[['hour']]\n",
    "y = df_raw['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c934737",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = LinearRegression()\n",
    "modelo.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(x_teste)\n",
    "rmse = np.sqrt(mean_squared_error(y_teste, y_pred))\n",
    "\n",
    "print(\"Coeficiente angular (slope):\", modelo.coef_[0])\n",
    "print(\"Intercepto:\", modelo.intercept_)\n",
    "print(\"R¬≤:\", r2_score(y_teste, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59603b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_teste, y_teste, color='gray', label='Real')\n",
    "plt.plot(x_teste, y_pred, color='blue', linewidth=2, label='Previs√£o')\n",
    "plt.title('Previs√£o da glicemia com base na hora do dia')\n",
    "plt.xlabel('Hora do dia')\n",
    "plt.ylabel('Glicemia (mg/dL)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696bd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
